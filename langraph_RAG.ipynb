{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX4AC58LzMfFvwERdCTtbU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radve88/Learning-AI/blob/main/langraph_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Hugging Face datasets library to load the dataset and convert it into a list of Document objects from the langchain.docstore.document module."
      ],
      "metadata": {
        "id": "Phb-yTOpXjFi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faqL7SKyV1Dv"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Load the dataset\n",
        "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
        "\n",
        "# Convert dataset entries into Document objects\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"\\n\".join([\n",
        "            f\"Name: {guest['name']}\",\n",
        "            f\"Relation: {guest['relation']}\",\n",
        "            f\"Description: {guest['description']}\",\n",
        "            f\"Email: {guest['email']}\"\n",
        "        ]),\n",
        "        metadata={\"name\": guest[\"name\"]}\n",
        "    )\n",
        "    for guest in guest_dataset\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code above, we:\n",
        "\n",
        "Load the dataset\n",
        "Convert each guest entry into a Document object with formatted content\n",
        "Store the Document objects in a list\n",
        "This means we‚Äôve got all of our data nicely available so we can get started with configuring our retrieval.\n",
        "\n",
        "Step 2: Create the Retriever Tool\n",
        "Now, let‚Äôs create a custom tool that Alfred can use to search through our guest information.\n",
        "We will use the BM25Retriever from the langchain_community.retrievers module to create a retriever tool."
      ],
      "metadata": {
        "id": "uI1us7yuXwca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.tools import Tool\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "\n",
        "def extract_text(query: str) -> str:\n",
        "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
        "    results = bm25_retriever.invoke(query)\n",
        "    if results:\n",
        "        return \"\\n\\n\".join([doc.page_content for doc in results[:3]])\n",
        "    else:\n",
        "        return \"No matching guest information found.\"\n",
        "\n",
        "guest_info_tool = Tool(\n",
        "    name=\"guest_info_retriever\",\n",
        "    func=extract_text,\n",
        "    description=\"Retrieves detailed information about gala guests based on their name or relation.\"\n",
        ")"
      ],
      "metadata": {
        "id": "nZQ95OkYX6H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs understand this tool step-by-step.\n",
        "\n",
        "The name and description help the agent understand when and how to use this tool\n",
        "The type decorators define what parameters the tool expects (in this case, a search query)\n",
        "We‚Äôre using a BM25Retriever, which is a powerful text retrieval algorithm that doesn‚Äôt require embeddings\n",
        "The method processes the query and returns the most relevant guest information\n",
        "Step 3: Integrate the Tool with Alfred\n",
        "Finally, let‚Äôs bring everything together by creating our agent and equipping it with our custom tool:"
      ],
      "metadata": {
        "id": "QVQcPuo8YOFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "\n",
        "# Generate the chat interface, including the tools\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm, verbose=True)\n",
        "tools = [guest_info_tool]\n",
        "chat_with_tools = chat.bind_tools(tools)\n",
        "\n",
        "# Generate the AgentState and Agent graph\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "def assistant(state: AgentState):\n",
        "    return {\n",
        "        \"messages\": [chat_with_tools.invoke(state[\"messages\"])],\n",
        "    }\n",
        "\n",
        "## The graph\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Define nodes: these do the work\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    # If the latest message requires a tool, route to tools\n",
        "    # Otherwise, provide a direct response\n",
        "    tools_condition,\n",
        ")\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "alfred = builder.compile()\n",
        "\n",
        "messages = [HumanMessage(content=\"Tell me about our guest named 'Lady Ada Lovelace'.\")]\n",
        "response = alfred.invoke({\"messages\": messages})\n",
        "\n",
        "print(\"üé© Alfred's Response:\")\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "lvMsjgZDYVtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What‚Äôs happening in this final step:\n",
        "\n",
        "We initialize a Hugging Face model using the HuggingFaceEndpoint class. We also generate a chat interface and append the tools.\n",
        "We create our agent (Alfred) as a StateGraph, that combines 2 nodes (assistant, tools) using an edge\n",
        "We ask Alfred to retrieve information about a guest named ‚ÄúLady Ada Lovelace‚Äù"
      ],
      "metadata": {
        "id": "_2y66UB-YeDA"
      }
    }
  ]
}