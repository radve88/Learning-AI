{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFBmguXBtWO7s6cU1ib3rs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radve88/Learning-AI/blob/main/llama_index_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fUy_iGtLT6Ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Hugging Face datasets library to load the dataset and convert it into a list of Document objects from the llama_index.core.schema module."
      ],
      "metadata": {
        "id": "XISYcagOT7Ig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOdc04jVTtK8"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from llama_index.core.schema import Document\n",
        "\n",
        "# Load the dataset\n",
        "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
        "\n",
        "# Convert dataset entries into Document objects\n",
        "docs = [\n",
        "    Document(\n",
        "        text=\"\\n\".join([\n",
        "            f\"Name: {guest_dataset['name'][i]}\",\n",
        "            f\"Relation: {guest_dataset['relation'][i]}\",\n",
        "            f\"Description: {guest_dataset['description'][i]}\",\n",
        "            f\"Email: {guest_dataset['email'][i]}\"\n",
        "        ]),\n",
        "        metadata={\"name\": guest_dataset['name'][i]}\n",
        "    )\n",
        "    for i in range(len(guest_dataset))\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n the code above, we:\n",
        "\n",
        "Load the dataset\n",
        "Convert each guest entry into a Document object with formatted content\n",
        "Store the Document objects in a list\n",
        "This means we‚Äôve got all of our data nicely available so we can get started with configuring our retrieval.Step 2: Create the Retriever Tool\n",
        "Now, let‚Äôs create a custom tool that Alfred can use to search through our guest information."
      ],
      "metadata": {
        "id": "w14hNqYVUDKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_defaults(nodes=docs)\n",
        "\n",
        "def get_guest_info_retriever(query: str) -> str:\n",
        "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
        "    results = bm25_retriever.retrieve(query)\n",
        "    if results:\n",
        "        return \"\\n\\n\".join([doc.text for doc in results[:3]])\n",
        "    else:\n",
        "        return \"No matching guest information found.\"\n",
        "\n",
        "# Initialize the tool\n",
        "guest_info_tool = FunctionTool.from_defaults(get_guest_info_retriever)"
      ],
      "metadata": {
        "id": "Swx__xr0UMRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs understand this tool step-by-step.\n",
        "\n",
        "The docstring helps the agent understand when and how to use this tool\n",
        "The type decorators define what parameters the tool expects (in this case, a search query)\n",
        "We‚Äôre using a BM25Retriever, which is a powerful text retrieval algorithm that doesn‚Äôt require embeddings\n",
        "The method processes the query and returns the most relevant guest information\n",
        "Step 3: Integrate the Tool with Alfred Finally, let‚Äôs bring everything together by creating our agent and equipping it with our custom tool:"
      ],
      "metadata": {
        "id": "S_3NYZMlUhyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "\n",
        "# Initialize the Hugging Face model\n",
        "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "# Create Alfred, our gala agent, with the guest info tool\n",
        "alfred = AgentWorkflow.from_tools_or_functions(\n",
        "    [guest_info_tool],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Example query Alfred might receive during the gala\n",
        "response = await alfred.run(\"Tell me about our guest named 'Lady Ada Lovelace'.\")\n",
        "\n",
        "print(\"üé© Alfred's Response:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "VWVkYJTBUkon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What‚Äôs happening in this final step:\n",
        "\n",
        "We initialize a Hugging Face model using the HuggingFaceInferenceAPI class\n",
        "We create our agent (Alfred) as a AgentWorkflow, including the tool we just created\n",
        "We ask Alfred to retrieve information about a guest named ‚ÄúLady Ada Lovelace‚Äù"
      ],
      "metadata": {
        "id": "V4G2jmgXUx1o"
      }
    }
  ]
}